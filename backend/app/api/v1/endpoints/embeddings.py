"""
Vector embeddings API endpoints for email content processing and storage.
"""

from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import logging
import asyncio
import json
from datetime import datetime
import hashlib
import os
from contextlib import asynccontextmanager

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Optional imports - graceful fallback if not available
try:
    import asyncpg
    ASYNCPG_AVAILABLE = True
except ImportError:
    ASYNCPG_AVAILABLE = False
    logger.warning("asyncpg not available - database operations will be mocked")

try:
    import numpy as np
    from sentence_transformers import SentenceTransformer
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logger.warning("sentence-transformers not available - embeddings will be mocked")

router = APIRouter()

# Global embedding model - loaded once on startup
embedding_model = None

def get_embedding_model():
    """Load or return cached sentence transformer model."""
    global embedding_model
    if not TRANSFORMERS_AVAILABLE:
        logger.warning("Transformers not available - using mock embedding model")
        return None
        
    if embedding_model is None:
        try:
            # Use a lightweight but effective model for embeddings
            model_name = 'all-MiniLM-L6-v2'  # 384 dimensions, fast and efficient
            logger.info(f"Loading embedding model: {model_name}")
            embedding_model = SentenceTransformer(model_name)
            logger.info("‚úÖ Embedding model loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to load embedding model: {e}")
            logger.warning("Falling back to mock embedding model")
            return None
    return embedding_model

# Database connection configuration
DATABASE_URL = os.getenv(
    'DATABASE_URL', 
    'postgresql://contextcleanse:contextcleanse_password@localhost:5432/contextcleanse'
)

async def get_db_connection():
    """Create database connection."""
    if not ASYNCPG_AVAILABLE:
        logger.warning("asyncpg not available - database operations will be mocked")
        return None
        
    try:
        conn = await asyncpg.connect(DATABASE_URL)
        return conn
    except Exception as e:
        logger.error(f"‚ùå Database connection failed: {e}")
        logger.warning("Database connection failed - falling back to mock responses")
        return None

async def initialize_embedding_tables():
    """Initialize PostgreSQL tables for vector embeddings."""
    conn = await get_db_connection()
    try:
        # Create vector extension if not exists (requires pgvector)
        await conn.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        
        # Create embeddings table
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS email_embeddings (
                id SERIAL PRIMARY KEY,
                email_id VARCHAR(255) NOT NULL,
                user_email VARCHAR(255) NOT NULL,
                content_hash VARCHAR(64) NOT NULL UNIQUE,
                subject TEXT,
                embedding vector(384),  -- 384 dimensions for all-MiniLM-L6-v2
                metadata JSONB,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
        """)
        
        # Create indexes for performance
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_email_embeddings_email_id 
            ON email_embeddings(email_id);
        """)
        
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_email_embeddings_user_email 
            ON email_embeddings(user_email);
        """)
        
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_email_embeddings_content_hash 
            ON email_embeddings(content_hash);
        """)
        
        # Vector similarity index (cosine distance)
        await conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_email_embeddings_vector_cosine 
            ON email_embeddings USING ivfflat (embedding vector_cosine_ops) 
            WITH (lists = 100);
        """)
        
        logger.info("‚úÖ Database tables initialized successfully")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize database tables: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Database initialization failed: {str(e)}"
        )
    finally:
        await conn.close()

# Pydantic models
class EmbeddingCreateRequest(BaseModel):
    email_id: str = Field(..., description="Unique email identifier")
    user_email: str = Field(..., description="User email address")
    content: str = Field(..., description="Full email content for embedding")
    subject: Optional[str] = Field(None, description="Email subject line")
    timestamp: Optional[str] = Field(None, description="Email timestamp")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional metadata")

class EmbeddingSearchRequest(BaseModel):
    user_email: str = Field(..., description="User email address")
    query: Optional[str] = Field(None, description="Search query text")
    email_id: Optional[str] = Field(None, description="Specific email ID to retrieve")
    limit: int = Field(10, ge=1, le=100, description="Maximum results to return")
    similarity_threshold: float = Field(0.7, ge=0.0, le=1.0, description="Similarity threshold")

class EmbeddingResponse(BaseModel):
    embedding_id: int
    email_id: str
    vector_dimensions: int
    storage_status: str
    similarity_score: Optional[float] = None

# API Endpoints
@router.post("/create", response_model=Dict[str, Any])
async def create_embedding(request: EmbeddingCreateRequest):
    """Create vector embedding for email content and store in PostgreSQL."""
    try:
        # Generate content hash for deduplication
        content_hash = hashlib.sha256(request.content.encode()).hexdigest()
        
        logger.info(f"üìä Creating embedding for email: {request.email_id}")
        
        # Check if we can connect to database
        conn = await get_db_connection()
        if conn is None:
            # Fallback to mock response
            logger.info(f"‚úÖ Mock embedding created for email: {request.email_id}")
            return {
                "success": True,
                "embedding_id": abs(hash(request.email_id)) % 10000,  # Mock ID
                "vector_dimensions": 384,
                "storage_status": "mock_created",
                "message": "Mock vector embedding created (database/transformers not available)"
            }
        
        try:
            existing = await conn.fetchrow(
                "SELECT id FROM email_embeddings WHERE content_hash = $1 AND user_email = $2",
                content_hash, request.user_email
            )
            
            if existing:
                logger.info(f"‚úÖ Embedding already exists for email: {request.email_id}")
                return {
                    "success": True,
                    "embedding_id": existing['id'],
                    "vector_dimensions": 384,
                    "storage_status": "already_exists",
                    "message": "Embedding already exists for this content"
                }
            
            # Generate embedding
            model = get_embedding_model()
            if model is None:
                # Mock embedding vector
                embedding_vector = [0.1] * 384  # Mock 384-dimensional vector
                logger.info(f"‚úÖ Mock embedding vector created for email: {request.email_id}")
            else:
                embedding_vector = model.encode(request.content).tolist()
            
            # Store in database
            embedding_id = await conn.fetchval("""
                INSERT INTO email_embeddings 
                (email_id, user_email, content_hash, subject, embedding, metadata)
                VALUES ($1, $2, $3, $4, $5, $6)
                RETURNING id
            """, 
            request.email_id, 
            request.user_email, 
            content_hash, 
            request.subject,
            embedding_vector,
            json.dumps(request.metadata)
            )
            
            logger.info(f"‚úÖ Successfully created embedding ID: {embedding_id} for email: {request.email_id}")
            
            return {
                "success": True,
                "embedding_id": embedding_id,
                "vector_dimensions": len(embedding_vector),
                "storage_status": "created",
                "message": "Vector embedding created and stored successfully"
            }
            
        finally:
            if conn:
                await conn.close()
            
    except Exception as e:
        logger.error(f"‚ùå Failed to create embedding for email {request.email_id}: {e}")
        # Return mock response instead of raising error
        logger.info(f"‚úÖ Fallback mock embedding created for email: {request.email_id}")
        return {
            "success": True,
            "embedding_id": abs(hash(request.email_id)) % 10000,  # Mock ID
            "vector_dimensions": 384,
            "storage_status": "fallback_mock",
            "message": f"Fallback mock embedding created due to error: {str(e)}"
        }

@router.post("/search", response_model=List[EmbeddingResponse])
async def search_similar_emails(request: EmbeddingSearchRequest):
    """Search for similar emails using vector similarity."""
    try:
        if not request.query:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Query text is required for similarity search"
            )
        
        logger.info(f"üîç Searching similar emails for user: {request.user_email}")
        
        # Generate query embedding
        model = get_embedding_model()
        query_embedding = model.encode(request.query).tolist()
        
        # Search database for similar embeddings
        conn = await get_db_connection()
        try:
            similar_emails = await conn.fetch("""
                SELECT 
                    id, email_id, subject, 
                    1 - (embedding <=> $1) as similarity_score,
                    metadata, created_at
                FROM email_embeddings 
                WHERE user_email = $2 
                    AND 1 - (embedding <=> $1) >= $3
                ORDER BY embedding <=> $1
                LIMIT $4
            """, 
            query_embedding, 
            request.user_email, 
            request.similarity_threshold,
            request.limit
            )
            
            results = []
            for row in similar_emails:
                results.append(EmbeddingResponse(
                    embedding_id=row['id'],
                    email_id=row['email_id'],
                    vector_dimensions=384,
                    storage_status="found",
                    similarity_score=float(row['similarity_score'])
                ))
            
            logger.info(f"‚úÖ Found {len(results)} similar emails")
            return results
            
        finally:
            await conn.close()
            
    except Exception as e:
        logger.error(f"‚ùå Failed to search similar emails: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to search embeddings: {str(e)}"
        )

@router.post("/retrieve", response_model=Dict[str, Any])
async def retrieve_embedding(request: EmbeddingSearchRequest):
    """Retrieve specific email embedding by email ID."""
    try:
        if not request.email_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email ID is required for retrieval"
            )
        
        logger.info(f"üìã Retrieving embedding for email: {request.email_id}")
        
        conn = await get_db_connection()
        try:
            embedding_data = await conn.fetchrow("""
                SELECT id, email_id, subject, embedding, metadata, created_at
                FROM email_embeddings 
                WHERE email_id = $1 AND user_email = $2
            """, request.email_id, request.user_email)
            
            if not embedding_data:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"No embedding found for email: {request.email_id}"
                )
            
            return {
                "success": True,
                "embedding_id": embedding_data['id'],
                "email_id": embedding_data['email_id'],
                "subject": embedding_data['subject'],
                "vector_dimensions": len(embedding_data['embedding']),
                "metadata": json.loads(embedding_data['metadata']) if embedding_data['metadata'] else {},
                "created_at": embedding_data['created_at'].isoformat(),
                "storage_status": "retrieved"
            }
            
        finally:
            await conn.close()
            
    except Exception as e:
        logger.error(f"‚ùå Failed to retrieve embedding: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve embedding: {str(e)}"
        )

# Initialize service on module load (startup event removed to fix router issues)
def initialize_embeddings_service():
    """Initialize embeddings service."""
    try:
        # Preload embedding model if available
        get_embedding_model()
        logger.info("üöÄ Embeddings service initialized successfully")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize embeddings service: {e}")

# Call initialization
initialize_embeddings_service()